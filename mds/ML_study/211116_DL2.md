---
marp: true
theme: custom
---
<!--
paginate: true
-->

<!--
_class: title
-->
# 深層学習
## 第2章: 深層ボルツマンマシン

### 久永健
#### 2021-11-16
<!-- 
[Ctrl] + [Alt] + [Shift] + [i]
で"Insert Date String"を用いて年月日を挿入できる. 
-->

---
# もくじ

1. **マルコフ確率場とボルツマンマシン**
2. ボルツマンマシン学習
3. ボルツマンマシン上での近似手法
4. 制限ボルツマンマシン
5. 深層ボルツマンマシン
6. 深層信念ネットワーク
7. まとめ

---
# マルコフ確率場とボルツマンマシン
<!-- 
_class: split
_header: "マルコフ確率場とボルツマンマシン"
-->

<div class=left>

## マルコフ確率場(MRF)
統計的機械学習の学習モデルの一つ
- エネルギー関数
	$$\Phi(\bm{x}) = -\sum_{i \in \bm{\Omega}} \phi(x_i) - \sum_{\{i, j\} \in \bm{\varepsilon}} \psi_{ij}(x_i, x_j)$$
- ギブス分布
	$$ p(\bm{X} = \bm{x}) = \frac{1}{Z} \exp(- \Phi(\bm{x})) \\
	 Z = \sum_{\bm{x}} \exp(-\Phi(\bm{x})) $$
</div>
<div class=right>

## ボルツマンマシン(BM)
MRFの最も単純なケース
- エネルギー関数
	$$\Phi(\bm{x}; \bm{\theta}) = -\sum_{i \in \bm{\Omega}} b_i x_i - \sum_{\{i, j\} \in \bm{\varepsilon}} w_{ij} x_i x_j$$
	$\bm{\theta} = \{\bm{b}, \bm{W}\}$
	- $\bm{b} = \{b_i | i \in \bm{\Omega}\}$
	- $\bm{\bm{W}} = \{w_{ij} | \{i, j\} \in \bm{\varepsilon}\}$

統計力学におけるイジングモデルと等価
</div>

---
# ポップフィールド・ネットワーク
<!--
_header: "マルコフ確率場とボルツマンマシン"
-->
- 無向グラフ$G(\bm{\Omega}, \bm{\varepsilon})$上に定義され, 各ノードをニューロン素子と見立てたNN
- ノード$i$は結合するすべてのノード$j$からの信号
$$\lambda_i = b_i + \sum_{j \in \mathcal{N}(i)} w_{ij} x_j$$

を受け取る. ここで$\mathcal{N}(i)$はノード$i$と結合されたノードの集合

- この入力信号$\lambda_i$が$0$を超えるとノード$i$が発火するような確定的NN

---
# ボルツマンマシン
<!--
_header: "マルコフ確率場とボルツマンマシン"
-->
- 入力信号$\lambda_i$から次の条件付き分布を計算する
$$p_{\text{sb}}(X_i = x_i | \lambda_i) = \frac{\exp(\lambda_i x_i)}{1 + \exp(\lambda_i)}$$
- これを, 入力信号を受け取った時のノード$i$の発火/非発火の分布としてみる
- 上記の条件付き分布$p_\text{sb}$はシグモイド信念と呼ばれる
- 入力信号$\lambda_i$を受け取った時のノード$i$が発火する確率は
$$p_{\text{sb}}(X_i = 1 | \lambda_i) = \frac{\exp(\lambda_i)}{1 + \exp(\lambda_i)} = \mathrm{sig}(\lambda_i)$$

---
# もくじ

1. マルコフ確率場とボルツマンマシン
2. **ボルツマンマシン学習**
3. ボルツマンマシン上での近似手法
4. 制限ボルツマンマシン
5. 深層ボルツマンマシン
6. 深層信念ネットワーク
7. まとめ

---
# 可視変数のみのボルツマンマシン学習
<!--
_header: "ボルツマンマシン学習"
-->
- BMの学習は一般的に**最尤推定**が用いられる. 
- 得られた観測データ点の集合$\mathcal{D} = \{\bm{v}^{(\mu)} | \mu = 1, 2, \cdots, N\}$に対して尤度関数
$$l_\mathcal{D}(\bm{\theta}) = \prod_{\mu = 1}^N p(\bm{V} = \bm{v}^{(\mu)} | \bm{\theta})$$
- 観測データ点の集合$\mathcal{D}$をBMが実際に生成する確率という解釈ができる
- 最尤推定により求まるBMは観測データ点の集合$\mathcal{D}$を最も高い確率で生成するBM

---
# 可視変数のみのボルツマンマシン学習
<!--
_header: "ボルツマンマシン学習"
-->
- 尤度関数の自然対数を**対数尤度関数**(単調増加)
$$L_\mathcal{D}(\bm{\theta}) = \ln l_\mathcal{D}(\bm{\theta}) = \sum_{\mu=1}^N \ln p(\bm{v}^{(\mu)} | \bm{\theta})$$
- 最大点でパラメータ$\bm{\theta}$に関する勾配が$0$となる. 
$$\frac{\partial L_\mathcal{D}}{\partial b_i} = \sum_{\mu=1}^N v_i^{(\mu)} - N \cdot \mathrm{E}_{p(\bm{V} | \bm{\theta})}[V_i] \\
\frac{\partial L_\mathcal{D}}{\partial w_{ij}} = \sum_{\mu=1}^N v_i^{(\mu)} v_j^{(\mu)} - N \cdot \mathrm{E}_{p(\bm{V} | \bm{\theta})}[V_i V_j]$$
ここで$\mathrm{E}_{p(\bm{V} | \bm{\theta})}[\cdots]$はBMに関する期待値

---
# 可視変数のみのボルツマンマシン学習
<!--
_header: "ボルツマンマシン学習"
-->
- ボルツマンマシンの学習方程式(可視変数のみ)
$$\frac{1}{N}\sum_{\mu=1}^N v_i^{(\mu)} = \mathrm{E}_{p(\bm{V} | \bm{\theta})}[V_i] \\
\frac{1}{N}\sum_{\mu=1}^N v_i^{(\mu)} v_j^{(\mu)} = \mathrm{E}_{p(\bm{V} | \bm{\theta})}[V_i V_j]$$

- 左辺: 観測データ点の標本平均(観測データ点の集合からすぐに得られる値)
- 右辺: それに対応するBMの期待値(確率変数の全可能な実現値の組み合わせの総和)

- 解析的に解くことが難しい $\Longrightarrow$ 一般的に計算機で数値的に解く

---
# KLダイバージェンスからの学習方程式
<!--
_header: "ボルツマンマシン学習"
-->
- KLダイバージェンスは確率変数$\bm{X}$に対する二つの異なる確率分布$p_0(\bm{X})$, $p_1(\bm{X})$の間のある種の非類似度を与える量
$$\mathrm{D}_{\text{KL}}(p_0 \| p_1) = \sum_{\bm{x}} p_0(\bm{x}) \ln \frac{p_0(\bm{x})}{p_1(\bm{x})}$$

- 経験分布: 観測データ点の頻度分布
$$q_\mathcal{D}(\bm{V} = \bm{v}) = \frac{1}{N} \sum_{\mu=1}^N \delta(\bm{v}, \bm{v}^{(\mu)}), ~~~ 
\delta(\bm{d}, \bm{e}) = \begin{cases}
	1 & \bm{d} = \bm{e} \\
	0 & \bm{d} \ne \bm{e}
\end{cases}$$
- 任意の関数$f(\bm{v})$の経験分布に関する期待値 = 観測データ点の標本平均
$$\sum_{\bm{v}} f(\bm{v}) q_\mathcal{D}(\bm{v}) = \frac{1}{N} \sum_{\mu=1}^N f(\bm{v}^{(\mu)})$$

---
# KLダイバージェンスからの学習方程式
<!--
_header: "ボルツマンマシン学習"
-->
- 経験分布とBMの間のKLダイバージェンス
$$\begin{align*}\mathrm{D}_{\text{KL}}(q_{\mathcal{D}} \| p) = \sum_{\bm{x}} q_{\mathcal{D}}(\bm{v}) \ln \frac{ q_{\mathcal{D}}(\bm{v})}{p(\bm{v} | \bm{\theta})} &= - \sum_{\bm{v}} q_{\mathcal{D}}(\bm{v}) \ln p(\bm{v} | \bm{\theta}) - \mathrm{H}(q_{\mathcal{D}}(\bm{V})) \\
&= - \frac{1}{N} L_{\mathcal{D}}(\bm{\theta}) - \mathrm{H}(q_{\mathcal{D}}(\bm{V}))
\end{align*}$$
- したがって, 以下が成り立つ
$$\arg \max_{\bm{\theta}} L_{\mathcal{D}}(\bm{\theta}) = \arg \min_{\bm{\theta}} \mathrm{D}_{\text{KL}}(q_{\mathcal{D}} \| p)$$

---
# ボルツマンマシン学習
<!--
_header: "ボルツマンマシン学習"
-->
```py
θ[0] = random()
t = 0

while θ[t] != θ[t+1]:
	for i in Ω:
		b[t+1, i] = b[t, i] + ε * (∂L/∂b[:, i])
	for i, j in Big_ε:
		w[t+1, i, j] = w[t, i, j] + ε * (∂L/∂w[:, i, j])
	t = t + 1
```
## 近似手法
- ギブスサンプリング
- 平均場近似

---
# 隠れ変数ありのボルツマンマシン学習
<!--
_header: "ボルツマンマシン学習"
-->
- より一般的なBM
$$p(\bm{X} = \bm{x} | \bm{\theta}) = p(\bm{V} = \bm{v}, \bm{H} = \bm{h} | \bm{\theta}) = \frac{1}{Z(\bm{\theta})} \exp(- \Phi(\bm{v}, \bm{h}; \bm{\theta}))$$

- 隠れ変数に関して周辺化した可変変数$\bm{V}$のみの分布を用いる.
$$p(\bm{v} | \bm{\theta}) = \sum_{\bm{h}} p(\bm{v}, \bm{h} | \bm{\theta})$$

- すべての可視変数に観測データ点が対応している. 
$$L_\mathcal{D}(\bm{\theta}) = \sum_{\mu=1}^N \ln p(\bm{v}^{(\mu)} | \bm{\theta})= N \sum_{\bm{v}}q_{\mathcal{D}}(\bm{v}) \ln p(\bm{v} | \bm{\theta})$$

- 前述のKLダイバージェンスを最小化することと等価

---
# 隠れ変数ありのボルツマンマシン学習
<!--
_header: "ボルツマンマシン学習"
-->
- パラメータに関するそれぞれの勾配
$$\frac{\partial L_\mathcal{D}}{\partial b_i} = N \sum_{\bm{v}, \bm{h}} x_i p(\bm{h} | \bm{v}, \bm{\theta}) q_{\mathcal{D}}(\bm{v}) - N \cdot \mathrm{E}_{p(\bm{V}, \bm{H} | \bm{\theta})}[X_i] \\
\frac{\partial L_\mathcal{D}}{\partial w_{ij}} =N \sum_{\bm{v}, \bm{h}} x_i x_j p(\bm{h} | \bm{v}, \bm{\theta}) q_{\mathcal{D}}(\bm{v}) - N \cdot \mathrm{E}_{p(\bm{V}, \bm{H} | \bm{\theta})}[X_i X_j]$$

- ボルツマンマシンの学習方程式(隠れ変数あり)
$$\sum_{\bm{v}, \bm{h}} x_i p(\bm{h} | \bm{v}, \bm{\theta}) q_{\mathcal{D}}(\bm{v}) = \mathrm{E}_{p(\bm{V}, \bm{H} | \bm{\theta})}[X_i] \\
\sum_{\bm{v}, \bm{h}} x_i x_j p(\bm{h} | \bm{v}, \bm{\theta}) q_{\mathcal{D}}(\bm{v}) = \mathrm{E}_{p(\bm{V}, \bm{H} | \bm{\theta})}[X_i X_j]$$

---
# 隠れ変数ありのボルツマンマシン学習
<!--
_header: "ボルツマンマシン学習"
-->
- 学習方程式の左辺は
$$\sum_{\bm{v}, \bm{h}} f(\bm{v}, \bm{h}) p(\bm{h} | \bm{v}, \bm{\theta}) q_{\mathcal{D}}(\bm{v}) = \frac{1}{N} \sum_{\mu=1}^N \sum_{\bm{h}} f(\bm{v}^{(\mu)}, \bm{h}) p(\bm{h} | \bm{v}^{(\mu)}, \bm{\theta})$$

- 各観測データ点$\bm{v}^{(\mu)}$ごとに隠れ変数のみのBM $p(\bm{h} | \bm{v}^{(\mu)}, \bm{\theta})$を求める
- さらにその期待値を計算する. 
- 以上を$\mu = 1, 2, \cdots, N$まで繰り返す. 
- すべて求めた後, 平均を計算する. 

隠れ変数ありの場合だと, 右辺, 左辺ともに**組み合わせ爆発**の問題が生じる. 

---
# 隠れ変数ありのボルツマンマシン学習
<!--
_header: "ボルツマンマシン学習"
-->
- 計算量的困難性の他にも, 問題あり
	- 隠れ変数ありの場合, 一般的に対数尤度関数はパラメータに対して凸性がない
	- 勾配上昇法の初期値が悪いと, 悪質な局所最適解に陥る恐れがある. 

- 隠れ変数を導入することでモデルの表現力が上がる

### エネルギー関数の関数系をより複雑なものに設計するアプローチ
- 高次BM
	- エネルギー関数に3変数以上の結合項を加えたモデル
	- 前述の2変数のみ結合を持つBMよりも一般に高い表現能力を持つ. 

---
# もくじ

1. マルコフ確率場とボルツマンマシン
2. ボルツマンマシン学習
3. **ボルツマンマシン上での近似手法**
4. 制限ボルツマンマシン
5. 深層ボルツマンマシン
6. 深層信念ネットワーク
7. まとめ

---
# ギブスサンプリング
<!--
_header: "ボルツマンマシン上での近似手法"
-->
- マルコフ連鎖モンテカルロ(MCMC)法の中で頻繁に利用されるサンプリング法
- $p(\bm{X} = \bm{x} | \bm{\theta})$に従い, $\bm{X}$に対応するサンプル点を多数発生させ標本平均を得ることで, BMの期待値を近似する方法. 

- BMだけでなく, 統計的機械学習の応用上の様々な場面で必要となる. 
- BMは変数同士の依存性が局所的である: (空間的)マルコフ性
$$p(X_i = x_i | \bm{X}_{-i} = \bm{x}_{-i}, \bm{\theta}) = \frac{p(\bm{x} | \bm{\theta})}{\sum_{x_i = 0,1} p(\bm{x} | \bm{\theta})} = p_{\mathrm{sb}}(X_i = x_i | \lambda_i)$$
- $X_i$は直接結合された変数からの影響しか受けない

---
# ギブスサンプリング
<!--
_header: "ボルツマンマシン上での近似手法"
-->
- 上記の条件付き分布に従って変数の値を確率的に逐次更新させていく方法
```py
x = random()

while sample not matched expected_sample:
	for i in Ω:
		p[i] = sig(Lambda[i])
		u = uniform()
		if p[i] >= u:
			x[i] = 1
		else :
			x[i] = 0
	sample = x
```
- 適当な初期値から出発してすぐには安定しない. 
- 初期段階のサンプル点は捨てて, しばらく更新させた後のサンプル点から実際のサンプル点を採用する手法がとられる

---
# ギブスサンプリング
<!--
_header: "ボルツマンマシン上での近似手法"
-->
- 全変数を更新するごとにサンプル点を出力すると, 前のサンプル点と次のサンプル点との相関が強くなってしまう
- 一回サンプルしたら, しばらくまた更新させた後の値をサンプルする. 

- ギブスサンプリングの手法で$K$個のサンプル点$\bm{s}^{(r)}$を得たとすると, BM上の注目する確率変数の期待値を対応するサンプル点の標本平均で近似できる. 
$$\mathrm{E}_{p(\bm{X} | \bm{\theta})}[X_i] \thickapprox \frac{1}{K} \sum_{r=1}^K s_i^{(r)}, ~~~ \mathrm{E}_{p(\bm{X} | \bm{\theta})}[X_i X_j] \thickapprox \frac{1}{K} \sum_{r=1}^K s_i^{(r)} s_j^{(r)}$$
- 大数の法則より, $K \rightarrow \infty$において近似は等号になる.
- そのためには非常に多くのサンプル点が必要となる. 

---
# 平均場近似
<!--
_header: "ボルツマンマシン上での近似手法"
-->
- 統計力学分野で生まれた近似計算法
- 期待値が容易に計算できるテスト分布を考え, KLダイバージェンスで測ってその分布の族の中でBMに最も近いものでBMを近似する. 
- 確率変数$\bm{X}$に対する既に因数分解された形式の確率分布(テスト分布)
$$q(\bm{X}) = \prod_{i \in \Omega} q_i(X_i)$$
- この分布の族の中でBMに最も近いものをBMの近似とする.
$$\mathrm{D}_{\mathrm{KL}}(q \| p) = \sum_{\bm{x}} q(\bm{x}) \ln \frac{q(\bm{x})}{p(\bm{x} | \bm{\theta})}$$

---
# 平均場近似
<!--
_header: "ボルツマンマシン上での近似手法"
-->
- 上の2式からラグランジュの未定乗数法を用いて条件付き最小化すると
$$q_i(x_i) = p_{\mathrm{sb}} \left(x_i | b_i + \sum_{j \in \mathcal{N}(i)} w_{ij} m_j \right)$$
ここで$m_i = \sum_{\bm{x}}x_i q(\bm{x}) = \sum_{x_i = 0, 1} x_i q_i(x_i)$
- 平均場方程式
$$m_i = \mathrm{sig} \left(b_i + \sum_{j \in \mathcal{N}(i)} w_{ij} m_j \right)$$

---
# 平均場近似
<!--
_header: "ボルツマンマシン上での近似手法"
-->　
```py
m[0] = random()

while m[t] != m[t+1]:
	for i in Ω:
		m[t+1, i] = sigmoid(b[i] + sum(w[i] * m[t]))
	t = t + 1
```
- 逐次代入法で求めれる. 

- 平均場近似はクラスタ変分法における第1近似, 第2近似は確率伝播法が導出される
- クラスタ変分法のさらなる高次の近似 $\Longrightarrow$ 一般化隔離伝播法

---
# もくじ

1. マルコフ確率場とボルツマンマシン
2. ボルツマンマシン学習
3. ボルツマンマシン上での近似手法
4. **制限ボルツマンマシン**
5. 深層ボルツマンマシン
6. 深層信念ネットワーク
7. まとめ

---
# 制限ボルツマンマシン
<!--
_header: "制限ボルツマンマシン"
-->
- RBMは完全2部グラフ上に定義された隠れ変数ありのボルツマンマシン
	- 可視層$\bm{V}$: 可視変数のみで構成
	- 隠れ層$\bm{H}$: 隠れ変数のみで構成
- RBMのエネルギー関数
$$\Phi (\bm{v}, \bm{h} | \bm{\theta}) = - \sum_{i \in \mathcal{V}} b_i v_i - \sum_{j \in \mathcal{H}} c_j h_j - \sum_{i \in \mathcal{V}} \sum_{j \in \mathcal{H}} w_{ij} v_i h_j $$

- RBMの確率モデル
$$p(\bm{V} = \bm{v}, \bm{H} = \bm{h} | \bm{\theta}) = \frac{1}{Z(\bm{\theta})} \exp (\sum_{i \in \mathcal{V}} b_i v_i + \sum_{j \in \mathcal{H}} c_j h_j + \sum_{i \in \mathcal{V}} \sum_{j \in \mathcal{H}} w_{ij} v_i h_j)$$

---
# 制限ボルツマンマシン
<!--
_header: "制限ボルツマンマシン"
-->
- 条件付き独立
$$p(X_1, X_2, \cdots, X_n | \bm{Y}) = \prod_{i=1}^n p(X_i | \bm{Y})$$
- 片方の層の確率変数が何らかの値に固定されると, もう片方の層の確率変数は互いに統計的に独立となる. 

- 層間(可視層, 隠れ層)の交互サンプリング(ブロック化サンプリング)ができる. 
	- いくつかの変数のグループごとに更新する
	- 確率変数$\bm{X}$をグループ$\bm{X}_0, \bm{X}_1$に分けて, それぞれの条件付き分布$p(\bm{X}_0 | \bm{X}_1), p(\bm{X}_1 | \bm{X}_0)$で交互に多変数の同時サンプリングを行う. 

---
# 制限ボルツマンマシンの学習
<!--
_header: "制限ボルツマンマシン"
-->
- RBMの可視変数$\bm{V}$のみの分布を求める. 
$$p(\bm{v} | \bm{\theta}) = \sum_{\bm{h}} p(\bm{v}, \bm{h} | \bm{\theta}) = \frac{1}{Z(\bm{\theta})} \exp \left(\sum_{i \in \mathcal{V}} b_i v_i + \sum_{j \in \mathcal{H}} \ln (1 + \exp (\lambda_j)) \right)$$

---
# 制限ボルツマンマシン
<!--
_header: "制限ボルツマンマシン"
-->

---
# 制限ボルツマンマシン
<!--
_header: "制限ボルツマンマシン"
-->

---
# 参考文献

- [1] a
- [2] b
- [3] c